{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Установка библиотек"
      ],
      "metadata": {
        "id": "uTS1ajBFYITg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обновляем datasets для избежания ошибки при использовании load_dataset\n",
        "!pip install --upgrade datasets\n",
        "\n",
        "# Устанавливаем фреймворк fireducks - быстрая библиотека DataFrame, разработанная для замены pandas, особенно в тех случаях, когда требуется повышенная скорость обработки данных\n",
        "!pip install fireducks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up1b4ZAuXm19",
        "outputId": "c8db8843-59a5-4cc3-a19a-102d081b744b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\n",
            "Collecting fireducks\n",
            "  Downloading fireducks-1.2.8-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting firefw==1.2.8 (from fireducks)\n",
            "  Downloading firefw-1.2.8-py3-none-any.whl.metadata (818 bytes)\n",
            "Requirement already satisfied: pandas<2.3.0,>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from fireducks) (2.2.2)\n",
            "Collecting pyarrow<19.1,>=19.0 (from fireducks)\n",
            "  Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.5.3->fireducks) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.5.3->fireducks) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.5.3->fireducks) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=1.5.3->fireducks) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=1.5.3->fireducks) (1.17.0)\n",
            "Downloading fireducks-1.2.8-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading firefw-1.2.8-py3-none-any.whl (12 kB)\n",
            "Downloading pyarrow-19.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, firefw, fireducks\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "Successfully installed fireducks-1.2.8 firefw-1.2.8 pyarrow-19.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт бибилотек и модулей"
      ],
      "metadata": {
        "id": "aQ2B_HqkYOPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Глубокое обучение\n",
        "import torch\n",
        "\n",
        "# Для генерации случайных чисел\n",
        "import random\n",
        "\n",
        "# Линейная алгебра\n",
        "import numpy as np\n",
        "\n",
        "# Pandas\n",
        "import fireducks.pandas as pd\n",
        "\n",
        "# Загрузка датасета\n",
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "# Трансформеры\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# Отключим мешаюшие предупреждения\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "pPKDO01hWklk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка модели"
      ],
      "metadata": {
        "id": "4mrSZWz7GyG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используем русскоязычную модель GPT от Сбера размера medium `sberbank-ai/rugpt3medium_based_on_gpt2`, чтобы она уместилась на GPU. Также укажем библиотеке pytorch, что вычисления мы будем проводить на графическом процессоре с поддержкой `cuda`:"
      ],
      "metadata": {
        "id": "Fm4BM84yHBjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda:0\")\n",
        "\n",
        "# Загрузка и инициализации модели и токенизатора\n",
        "model_name = \"ai-forever/rugpt3medium_based_on_gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name).to(DEVICE)"
      ],
      "metadata": {
        "id": "j5nf1RczI-4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы проверить, что используемый объект tokenizer действительно поддерживается используется его атрибут is_fast:"
      ],
      "metadata": {
        "id": "YOUqv8toPWXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.is_fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwS3lGczOnW0",
        "outputId": "816361c8-cd52-4028-ca79-edcd7f78859f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка и подготовка датасета"
      ],
      "metadata": {
        "id": "Z87vVf4pYZzm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве датасета будем использовать **MLSUM**, крупномасштабный набор данных для многоязычной суммаризации. Данные извлечены из онлайн-газет и содержат более 1,5 млн пар статья/резюме на пяти различных языках - французском, немецком, испанском, русском и турецком. Загрузим **RU** данные:"
      ],
      "metadata": {
        "id": "JCGIWeqAxGPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"mlsum\", \"ru\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "n0hWoMwVJASc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Структура данных:"
      ],
      "metadata": {
        "id": "TlCXqroYx3kK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9y0H-rxX0v_",
        "outputId": "f234fe9b-9b80-43ce-b283-c68b13c1d9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'summary', 'topic', 'url', 'title', 'date'],\n",
              "        num_rows: 25556\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'summary', 'topic', 'url', 'title', 'date'],\n",
              "        num_rows: 750\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'summary', 'topic', 'url', 'title', 'date'],\n",
              "        num_rows: 757\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на пример данных:"
      ],
      "metadata": {
        "id": "S57fUG7WYomk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Text: \", dataset[\"train\"][0][\"text\"])\n",
        "print(\"Summary: \", dataset[\"train\"][0][\"summary\"])\n",
        "print(\"Topic: \", dataset[\"train\"][0][\"topic\"])\n",
        "print(\"URL: \", dataset[\"train\"][0][\"url\"])\n",
        "print(\"Title: \", dataset[\"train\"][0][\"title\"])\n",
        "print(\"Date: \", dataset[\"train\"][0][\"date\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTY1qlRKYqvv",
        "outputId": "c0a86cd4-2add-456e-9bc3-b26db81b94ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  Сладострастник в течение трех лет преследовал подростка в надежде совратить его. Как сообщили “МК” в следственном отделе по Хорошевскому району СУ СК при Прокуратуре РФ по Москве, 26 августа 2006 года 13-летний Павел вместе с другом отдыхал на берегу Москвы–реки рядом с Крылатским мостом. Там к ребятам подошел мужчина. Новый знакомый представился Евгением и предложил вместе пообедать в ресторане быстрого питания, а потом искупаться. Именно там, на берегу, педагог начал приставать к мальчику. Школьник убежал, но педофил успел снять голого подростка на мобильный телефон. После этого жизнь мальчика превратилась в сущий ад. Евгений узнал, где живет Павел, и стал шантажировать его. Этот кошмар продолжался три года. Преподаватель угрожал показать фотографию друзьям и знакомым Павла. Негодяй исписал непотребными надписями стены подъезда, где проживали друзья школьника. В один из дней он приехал в Сергиев Посад, к бабушке мальчика, и там накинулся на школьника с ножом. Наконец, отчаявшийся подросток рассказал обо всем матери, и та обратилась в милицию. Первый раз стражи порядка упустили 43-летнего педофила (к слову, он разведен). Милиционеры нагрянули в его квартиру, а Евгений под предлогом прощания с мамой-инвалидом зашел в соседнюю комнату, выпрыгнул из окна и был таков. Задержать извращенца стражам порядка помогла случайность. Несколько дней назад мать Павла увидела Евгения на станции метро “Александровский сад”. На мужчине красовался парик, но женщина узнала негодяя в толпе. Милиционеры, дежурившие на станции, по просьбе дамы задержали растлителя. В его кармане они обнаружили нож. Кстати, за несколько дней до задержания мужчина подкараулил Павла на улице и ударил его по лицу, обзывая нехорошими словами. Всех, чьи дети стали жертвами педофила, просят звонить по телефону 8-499-197-88-17 или 02.\n",
            "Summary:  Старший преподаватель института коммунального хозяйства и строительства был задержан на днях в Москве за растление школьника\n",
            "Topic:  incident\n",
            "URL:  https://www.mk.ru/incident/article/2010/01/05/409052-pedofil-presledoval-podrostka-tri-goda.html\n",
            "Title:  Педофил преследовал подростка три года\n",
            "Date:  06/01/2010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим какие значения принимает столбец 'topic':"
      ],
      "metadata": {
        "id": "1Ydi5PJS3jqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(dataset[\"train\"][\"topic\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qub7kDn73Dqa",
        "outputId": "fbdc0cd9-72a6-4686-fee9-6ded8b29613b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['auto', 'culture', 'daily', 'economics', 'editions', 'incident',\n",
              "       'moscow', 'mosobl', 'nasha-moskva', 'new-year-2016', 'politics',\n",
              "       'science', 'social', 'specprojects', 'sport', 'zloba-dnya'],\n",
              "      dtype='<U13')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Т.к. перед нами стоит задача научить GPT по русскоязычным текстам новостей писать заголовки к ним, следует удалить лишние колонки: 'summary', 'topic', 'url', 'date'."
      ],
      "metadata": {
        "id": "cbMvxkeKyKF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Столбцы, которые нужно удалить\n",
        "columns_to_remove = ['summary', 'topic', 'url', 'date']\n",
        "\n",
        "# Удаляем столбцы во всех частях датасета (train/val/test)\n",
        "dataset = dataset.remove_columns(columns_to_remove)\n",
        "\n",
        "# Проверяем оставшиеся столбцы\n",
        "print(dataset[\"train\"].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbxS3vn46c7F",
        "outputId": "210d731b-4889-4c3c-f941-9e8342765d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'title']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим на null значения:"
      ],
      "metadata": {
        "id": "QJBtMQJjDkUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for split in dataset:\n",
        "    print(f\"\\nSplit: {split}\")\n",
        "    for column in dataset[split].column_names:\n",
        "        null_count = sum(1 for item in dataset[split][column] if item is None)\n",
        "        print(f\"Столбец '{column}': {null_count} null значений\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVwCmuhi3HcU",
        "outputId": "42d74a51-1b0c-47c4-f40c-95c7feae2fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Split: train\n",
            "Столбец 'text': 0 null значений\n",
            "Столбец 'title': 0 null значений\n",
            "\n",
            "Split: validation\n",
            "Столбец 'text': 0 null значений\n",
            "Столбец 'title': 0 null значений\n",
            "\n",
            "Split: test\n",
            "Столбец 'text': 0 null значений\n",
            "Столбец 'title': 0 null значений\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Уменьшаем train до 1000 строк (выбираем первые 10000):"
      ],
      "metadata": {
        "id": "65Flfz1PVTlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_train = dataset[\"train\"].select(range(10000))\n",
        "\n",
        "# Создаем новый DatasetDict с уменьшенным train\n",
        "df = DatasetDict({\n",
        "    \"train\": small_train,\n",
        "    \"validation\": dataset[\"validation\"],  # валидация без изменений\n",
        "    \"test\": dataset[\"test\"]              # тест без изменений\n",
        "})"
      ],
      "metadata": {
        "id": "TEIPHxOsXjcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV9Y9e_QXvXQ",
        "outputId": "d2b072f0-136b-4562-8cb5-eceb7b293341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'title'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'title'],\n",
              "        num_rows: 750\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'title'],\n",
              "        num_rows: 757\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отлично! Null значений нет."
      ],
      "metadata": {
        "id": "7XgamyzeD5qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подготовка обучающих данных"
      ],
      "metadata": {
        "id": "yGU-DD2oPCpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовка данных"
      ],
      "metadata": {
        "id": "rDwjldfiU-WY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_examples(examples):\n",
        "    texts = examples[\"text\"]\n",
        "    titles = examples[\"title\"]\n",
        "    inputs = [f\"{text}\\n\\nЗаголовок: {title}<|endoftext|>\" for text, title in zip(texts, titles)]\n",
        "    return {\"formatted\": inputs}"
      ],
      "metadata": {
        "id": "Gceh_aZDVASw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = {\n",
        "    \"train\": df[\"train\"].map(prepare_examples, batched=True, remove_columns=[\"text\", \"title\"]),\n",
        "    \"validation\": df[\"validation\"].map(prepare_examples, batched=True, remove_columns=[\"text\", \"title\"])\n",
        "}"
      ],
      "metadata": {
        "id": "eqrNUSIAJCZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Токенизация"
      ],
      "metadata": {
        "id": "g9hMQAAvVEJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"formatted\"], truncation=True, max_length=512)"
      ],
      "metadata": {
        "id": "2htvrguQVFNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets[\"train\"] = tokenized_datasets[\"train\"].map(tokenize_function, batched=True, remove_columns=[\"formatted\"])\n",
        "tokenized_datasets[\"validation\"] = tokenized_datasets[\"validation\"].map(tokenize_function, batched=True, remove_columns=[\"formatted\"])"
      ],
      "metadata": {
        "id": "JIvBQIDdJDGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataCollator для языкового моделирования"
      ],
      "metadata": {
        "id": "q0jZHg5AVnfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # Мы не используем masked language modeling\n",
        ")"
      ],
      "metadata": {
        "id": "0GbjlisYVouc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оичщаем память:"
      ],
      "metadata": {
        "id": "2Y_-6fOrZeRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del dataset, small_train"
      ],
      "metadata": {
        "id": "BIDtYO2aYjwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение"
      ],
      "metadata": {
        "id": "KgU20qBuHoa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./finetuned\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=True if DEVICE == \"cuda\" else False,\n",
        ")"
      ],
      "metadata": {
        "id": "kv2uQciYU30t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "6hsfW582Vy30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запускаем обучение:"
      ],
      "metadata": {
        "id": "eP83vH7YOsKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "X1V-ngIXOsei",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "b3e260b8-ae78-4629-b2c1-c5f5a54e35fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnesterenkoms2001\u001b[0m (\u001b[33mnesterenkoms2001-digitaltech\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250613_083319-wd4c0crk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nesterenkoms2001-digitaltech/huggingface/runs/wd4c0crk' target=\"_blank\">./finetuned</a></strong> to <a href='https://wandb.ai/nesterenkoms2001-digitaltech/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nesterenkoms2001-digitaltech/huggingface' target=\"_blank\">https://wandb.ai/nesterenkoms2001-digitaltech/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nesterenkoms2001-digitaltech/huggingface/runs/wd4c0crk' target=\"_blank\">https://wandb.ai/nesterenkoms2001-digitaltech/huggingface/runs/wd4c0crk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7500/7500 3:34:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.020600</td>\n",
              "      <td>3.031713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.777200</td>\n",
              "      <td>3.038888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.593900</td>\n",
              "      <td>3.060896</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7500, training_loss=2.8386087890625, metrics={'train_runtime': 12907.5867, 'train_samples_per_second': 2.324, 'train_steps_per_second': 0.581, 'total_flos': 2.7811328093208576e+16, 'train_loss': 2.8386087890625, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сохранение модели"
      ],
      "metadata": {
        "id": "EPhlpZQxy9x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение модели и токенизатора\n",
        "model.save_pretrained(\"./news_title_generator\")\n",
        "tokenizer.save_pretrained(\"./news_title_generator\")"
      ],
      "metadata": {
        "id": "p1QvVJ5HT4iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загружаем модель"
      ],
      "metadata": {
        "id": "oUtBvKjdzA-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda:0\")\n",
        "\n",
        "# Путь к сохранённой модели\n",
        "model_path = \"./news_title_generator\"\n",
        "\n",
        "# Загрузка токенизатора\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Загрузка модели\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path).to(DEVICE)\n",
        "\n",
        "# Проверка загрузки\n",
        "print(\"Модель и токенизатор успешно загружены!\")\n",
        "print(f\"Архитектура модели: {model.__class__.__name__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VouuTXbXQ-Ia",
        "outputId": "51542110-b19a-49da-e51c-50196e56efb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель и токенизатор успешно загружены!\n",
            "Архитектура модели: GPT2LMHeadModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тестирование"
      ],
      "metadata": {
        "id": "Vts2Cc1azEmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_title(text, max_new_tokens=50):\n",
        "    # Формируем промпт с явным разделителем\n",
        "    prompt = f\"Текст: {text}\\nЗаголовок:\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True).to(DEVICE)\n",
        "\n",
        "    # Генерация с явным указанием токенов\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        num_beams=5,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "    # Декодируем и очищаем вывод\n",
        "    full_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    title = full_output.replace(prompt, \"\").strip()\n",
        "\n",
        "    # Удаляем возможные HTML-теги и специальные символы\n",
        "    title = title.split('<|endoftext|>')[0].split('</p>')[0].strip()\n",
        "\n",
        "    return title"
      ],
      "metadata": {
        "id": "wuFTiHoVNvgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним проверку на тестовых примерах из датасета:"
      ],
      "metadata": {
        "id": "cuQNV_SczRTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_comparison_table(dataset_dict):\n",
        "    # Преобразуем тестовый набор данных в DataFrame\n",
        "    df = dataset_dict['test'].to_pandas()\n",
        "\n",
        "    # Функция для обрезки текста до 100 слов\n",
        "    def truncate_to_100_words(text):\n",
        "        words = text.split()[:100]  # Берем первые 100 слов\n",
        "        return ' '.join(words)\n",
        "\n",
        "    # Применяем обрезку ко всем текстам\n",
        "    df['text'] = df['text'].apply(truncate_to_100_words)\n",
        "\n",
        "    # Выбираем 5 случайных примеров из датасета\n",
        "    random_samples = df.sample(n=10)\n",
        "\n",
        "    # Создаем строки для вывода\n",
        "    output_lines = []\n",
        "\n",
        "    for i, (_, row) in enumerate(random_samples.iterrows(), 1):\n",
        "        original_text = row['text']\n",
        "        original_title = row['title']\n",
        "        predicted_title = generate_title(original_text)\n",
        "\n",
        "        output_lines.append(f\"Пример {i}\")\n",
        "        output_lines.append(f\"Оригинальный текст: {original_text}\")\n",
        "        output_lines.append(f\"Оригинальный заголовок: {original_title}\")\n",
        "        output_lines.append(f\"Предсказанный заголовок: {predicted_title}\")\n",
        "        output_lines.append(\"\")  # Пустая строка между примерами\n",
        "\n",
        "    # Объединяем все строки с переносами\n",
        "    return '\\n'.join(output_lines)"
      ],
      "metadata": {
        "id": "1XhFVzQwFAJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comparison_table = generate_comparison_table(df)\n",
        "print(comparison_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7e2AjWEWNVU",
        "outputId": "56053d38-3482-40ac-be36-357bde2ffbf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример 1\n",
            "Оригинальный текст: — Юлия Викторовна, расскажите для начала, в чем заключается основная задача логопеда? — Я бы сказала так: логопед — это главный специалист в дошкольном детстве. Логопед занимается не только развитием общей речевой активности, фонематического слуха, коррекцией звукопроизношения, накоплением словаря, развитием грамматической стороны речи, обучением навыкам словообразования, развитием связной речи, но и развитием психических процессов — внимание, память, восприятие, мышление, формирует предпосылки обучения грамоте, т.е. дает понятия «звук», «слово», «предложение», занимается развитием общей и мелкой моторики. Логопедия всегда стояла на стыке таких наук, как педагогика, психология, нейропсихология, психолингвистика, физиология и неврология. Для того чтобы скорректировать дефект, логопед должен обладать всеми этими\n",
            "Оригинальный заголовок: Логопед рассказала, как воспитать умного ребенка\n",
            "Предсказанный заголовок: Как научить ребенка говорить правильно?\n",
            "\n",
            "Пример 2\n",
            "Оригинальный текст: — Сбор подписей дался нам очень сложно. Во-первых, нужно было собрать более 6000 подписей. Мы собирали в пикетах, ходили по квартирам. При этом в пикетах мы собрали примерно 1500 подписей, по квартирам всю остальную часть. — Что сложнее — собирать подписи в пикетах или по квартирам? — Ходить по квартирам, когда нам открывают дверь только в 10–20% случаев, — сложно. Я знаю это на собственном опыте — сама ходила по квартирам и стояла в пикетах после работы и по выходным. Кроме подписей собирала и так называемые наказы. — Когда ваш штаб начал работу? — Мы начали за полтора месяца до\n",
            "Оригинальный заголовок: Зарегистрированный кандидат в депутаты Мосгордумы рассказала о трудностях начала кампании\n",
            "Предсказанный заголовок: “Сбор подписей — это очень сложный процесс”\n",
            "\n",
            "Пример 3\n",
            "Оригинальный текст: Премьер-министр Грузии Мамука Бахтадзе призвал всех подчиниться решению ЕСПЧ и напомнил, что «Невыполнение решения суда карается законом». В четверг ЕСПЧ вынес вердикт по жалобе юристов телекомпании \"Рустави 2\" на решение Верховного суда Грузии, который в марте 2017 года признал законным владельцем телекомпании Кибара Халваши. Претензии жалобщиков ЕСПЧ счел необоснованными. Кибар Халваши был другом экс-министра обороны Грузии Ираклия Окруашвили. Бывший ближайший соратник Саакашвили, Окруашвили перешел в оппозицию, осенью 2007 года он был арестован, а затем после уплаты залога в 10 миллионов лари освобожден и покинул страну. За три дня до ареста Окруашвили, 24 сентября 2007 года, были опечатаны все офисы и\n",
            "Оригинальный заголовок: Рустави-2 выбили из рук Саакашвили: уволенный гендиректор потребовал $5 млн\n",
            "Предсказанный заголовок: Грузия не признает решения Европейского суда по правам человека\n",
            "\n",
            "Пример 4\n",
            "Оригинальный текст: Как умирали «вор» Вася Бриллиант и террорист Салман Радуев Расположенный в Пермском крае Соликамск — городок небольшой, известный своими шахтами по добыче соли и колонией для пожизненно осужденных «Белый лебедь». Как некоторые иронизируют, местное население состоит из шахтеров, тюремщиков и заключенных. Знакомство с «Белым лебедем» можно начинать на... городском кладбище. Здесь, на окраине, хоронили и хоронят заключенных. И самая приметная могила с памятником в виде купола — легенды криминального мира Василия Бабушкина по кличке Вася Бриллиант (прозвище получил за «чистоту соблюдения воровского кодекса»), с которого, по сути, началась главная страница в истории «Белого лебедя». — Его привезли при мне, в\n",
            "Оригинальный заголовок: \"Птенцы «Белого лебедя»: как умирали вор \"\"Бриллиант\"\" и террорист Салман Радуев\"\n",
            "Предсказанный заголовок: «Вор в законе» Василий Бабушкин умер в тюрьме\n",
            "\n",
            "Пример 5\n",
            "Оригинальный текст: Для тех, кто провинился — опоздал на «уточниловку», которая проходила ровно в десять утра и ни минутой позже, не огласил «весь список, пжлста» материалов, идущих в номер от конкретного отдела редакции, вообще натворил чудес в течение дня, эта книжка становилась настоящим кондуитом. Одна строчка от руки в дневнике происшествий могла собрать экстренный сбор редколлегии, по итогам которой сотрудника ждала кара — от выговора до увольнения. В зависимости от масштаба проступка. Ах, если бы найти сегодня все бесценные фолианты, на страницах которых дежурные редакторы и свежие головы (сотрудники, приступавшие к отлавливанию ошибок в шесть вечера) изливали душу в самой непринужденной литературной\n",
            "Оригинальный заголовок: \"Дежурка и свежие головы: как работал \"\"МК\"\" в семидесятые\"\n",
            "Предсказанный заголовок: «Уточняющие» дневники\n",
            "\n",
            "Пример 6\n",
            "Оригинальный текст: На 45 мандатов Мосгордумы выдвинулись 426 кандидатов — представители 19 политических партий и самовыдвиженцы, напомнил Валентин Горбунов. Все кандидаты, кроме представителей парламентских партий, обязаны были сдать подписи избирателей в количестве 3% от списочного состава — в среднем, по словам Горбунова, это 4500 подписей. — До окружных избирательных комиссий к 6 июля дошли 290 кандидатов, — рассказал чиновник. — Остальные так или иначе снялись с выборов. Из них зарегистрировали 233 человека, в том числе 171 партийного кандидата. 45 кандидатов идут от ЛДПР, 44 от КПРФ, 40 от «Справедливой России». Зарегистрированы и кандидаты от непарламентских партий: 32 от «Коммунистов России», 4 от\n",
            "Оригинальный заголовок: На выборы в Мосгордуму выходят 233 кандидата\n",
            "Предсказанный заголовок: В Москве пройдут выборы мэра\n",
            "\n",
            "Пример 7\n",
            "Оригинальный текст: На такую, прямо скажем, сенсационную оценку, да еще от первого лица, трудно было не обратить внимание. Народ в соцсетях оживился, началось бурное обсуждение среди врачей и пациентов. Однако, как ни странно, ни ликования по поводу внимания, оказанного столь важной проблеме, как здравоохранение, ни вообще какого-либо позитива в восприятии не было. В комментариях — а их многие сотни — сквозил пессимизм, и даже ненависть. Как случилось, что советские люди потеряли веру в счастливое будущее? Давайте разберемся. Что предлагает наш дорогой и горячо любимый президент? Если коротко: 1. Закачать еще немерено деньжищ в здравоохранение. 2. Врачам платить больше, больше, и еще больше.\n",
            "Оригинальный заголовок: \"\"\"В больнице что, работают врачи с другой планеты?!\"\"\"\n",
            "Предсказанный заголовок: У нас все хорошо!\n",
            "\n",
            "Пример 8\n",
            "Оригинальный текст: Родился здоровым ребенком со стопроцентным зрением Существующие сегодня программы в смартфонах значительно облегчили жизнь незрячих людей. Во время нашей беседы из смартфона Алексея постоянно раздавались озвученные сообщения из многочисленных мессенджеров и «голоса» свежих новостей из Интернета. А еще у него наручные часы с экранным диктором. Он самостоятельно и очень быстро пишет эсэмэски и отвечает на электронные письма. 20 лет назад о таких чудесах техники люди с потерей зрения могли только мечтать. — Это журналисты отчасти виноваты, что общество считает слепых людей слабыми, беспомощными. Пишут слезливые истории, — начал нашу беседу Алексей Черемуш. — А вы знаете, какие из слепых девушек\n",
            "Оригинальный заголовок: История жизни и любви слепого музыканта: «Муж не был мне обузой»\n",
            "Предсказанный заголовок: Слепоглухонемой человек\n",
            "\n",
            "Пример 9\n",
            "Оригинальный текст: - Алексей, почему в 21-м веке мы до сих пор не можем исключить случайное попадание птиц в самолеты? - Да, даже сегодня, в век высоких технологий, нет стопроцентной гарантии избавления от столкновения с пернатыми. А дело вот в чем: весной и осенью – в нашем случае с середины августа - начинаются миграции перелетных птиц, подрастает молодняк, он начинает становиться на крыло. Плюс начинаются миграции и службы контроля полетов вынуждены это учитывать и строить маршруты, чтобы избегать птичьих стай. - То есть фактор природы как влиял на заре авиации, так и сейчас влияет на безопасность полетов? - Птицы не спрашивают нас,\n",
            "Оригинальный заголовок: Эксперт оценил «птичью угрозу» для безопасности полетов: как избежать столкновения\n",
            "Предсказанный заголовок: Летчики не знают, что делать с птицами\n",
            "\n",
            "Пример 10\n",
            "Оригинальный текст: — Тема долговременного ухода для нашей страны новая. И хотя мы уже писали об этом, все же попрошу напомнить: что такое «долговременный уход за пожилыми людьми»? — Долговременный уход — это предоставление нуждающимся людям максимально профессиональных услуг в максимально привычной для них обстановке. Мы меняем систему социального обслуживания: приоритеты, цели, технологию ухода. Она должна соответствовать самым успешным общемировым, напрямую влиять на продолжительность активной жизни. Привычная обстановка — это, как правило, дом. Поэтому стационар (дом престарелых или психоневрологический интернат) должен быть крайней мерой. Хотя выбор всегда остается за человеком — именно за самим человеком, а не за его родственниками. Важно по\n",
            "Оригинальный заголовок: Государство учится обеспечивать гражданам нормальную старость\n",
            "Предсказанный заголовок: Долгожданный уход\n",
            "\n"
          ]
        }
      ]
    }
  ]
}